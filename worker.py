import time
import json
import requests
import statistics
import logging
import sys
from datetime import datetime, timedelta
import os
import warnings # â­ ê²½ê³ ë¥¼ ì œì–´í•˜ê¸° ìœ„í•´ ì¶”ê°€

# ---------------------------------------------------------
# ğŸ› ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
# ---------------------------------------------------------
try:
    import boto3
    from botocore.exceptions import ClientError
except ImportError:
    print("âŒ boto3 ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. requirements.txtì— boto3ë¥¼ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

# ---------------------------------------------------------
# ğŸ“ ë¡œê¹… ì„¤ì • (Docker ë¡œê·¸ í™•ì¸ìš©)
# ---------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)] # í‘œì¤€ ì¶œë ¥ìœ¼ë¡œ ë‚´ë³´ë‚´ì•¼ ë„ì»¤ ë¡œê·¸ì—ì„œ ë³´ì„
)
logger = logging.getLogger()

# =========================================================
# âš™ï¸ ì„¤ì •ê°’ (AWS & API & Backend)
# =========================================================

# 1. AWS SQS ì„¤ì •
QUEUE_URL = "https://sqs.us-east-1.amazonaws.com/730335221432/smart-sourcing-queue"
AWS_REGION = 'us-east-1'

# 2. ë„¤ì´ë²„ API í‚¤ (í•˜ë“œì½”ë”© ë¨ - ë³´ì•ˆìƒ í™˜ê²½ë³€ìˆ˜ ê¶Œì¥í•˜ë‚˜ í¸ì˜ë¥¼ ìœ„í•´ ìœ ì§€)
NAVER_CLIENT_ID = "I1uLlyo_ne_BHszaVd3R"
NAVER_CLIENT_SECRET = "swMHAs3qpq"

# 3. Spring Boot ë°±ì—”ë“œ ì£¼ì†Œ (ALB ì£¼ì†Œ ì ìš©)
# Docker ë‚´ë¶€ì—ì„œëŠ” localhostê°€ ì•„ë‹Œ ì™¸ë¶€ ALB ì£¼ì†Œë¥¼ ë°”ë¼ë´ì•¼ í•©ë‹ˆë‹¤.
DEFAULT_API_URL = "http://smartsourcing-alb-new-409803492.us-east-1.elb.amazonaws.com"
SPRING_BOOT_API = os.getenv("SPRING_BOOT_API_URL", DEFAULT_API_URL).rstrip('/') # ëì— /ê°€ ìˆìœ¼ë©´ ì œê±°

# SQS í´ë¼ì´ì–¸íŠ¸ ìƒì„±
try:
    sqs_client = boto3.client('sqs', region_name=AWS_REGION)
except Exception as e:
    logger.error(f"âŒ AWS SQS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    sys.exit(1)


# =========================================================
# ğŸ“¡ ì™¸ë¶€ API ì—°ë™ í•¨ìˆ˜ë“¤
# =========================================================

# 1. ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ API
def get_naver_shopping_data(keyword):
    url = "https://openapi.naver.com/v1/search/shop.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {"query": keyword, "display": 100, "sort": "sim"}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=5)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError:
        logger.error(f"âŒ [ë„¤ì´ë²„ ì‡¼í•‘ API ì—ëŸ¬] í‚¤ì›Œë“œ: {keyword} | ìƒíƒœì½”ë“œ: {response.status_code}")
        return {"items": []}
    except Exception as e:
        logger.error(f"âŒ [ë„¤ì´ë²„ ì‡¼í•‘ API ì—°ê²° ì‹¤íŒ¨]: {e}")
        return {"items": []}

# 2. ë„¤ì´ë²„ ë°ì´í„°ë© íŠ¸ë Œë“œ API
def get_naver_datalab_trend(keyword):
    today = datetime.now()
    start_date = (today - timedelta(days=30)).strftime('%Y-%m-%d')
    end_date = today.strftime('%Y-%m-%d')

    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    body = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "date",
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}],
    }

    try:
        res = requests.post(url, headers=headers, json=body, timeout=5)
        res.raise_for_status()
        data = res.json()

        # ìµœê·¼ 7ì¼ í‰ê· ê°’ ê³„ì‚°
        if "results" in data and data["results"]:
            recent = [d["ratio"] for d in data["results"][0]["data"][-7:]]
            return int(statistics.mean(recent)) if recent else 0
        return 0
    except Exception as e:
        logger.warning(f"âš ï¸ [ë°ì´í„°ë© API ì‹¤íŒ¨] í‚¤ì›Œë“œ: {keyword} (ê¸°ë³¸ê°’ 0 ì²˜ë¦¬) - {e}")
        return 0


# =========================================================
# ğŸ§  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (ë¶„ì„ ë° ë­í‚¹)
# =========================================================

CATEGORY_KEYWORD_MAP = {
    "íŒ¨ì…˜ì˜ë¥˜": "ê²¨ìš¸ì˜·",
    "í™”ì¥í’ˆ/ë¯¸ìš©": "í™”ì¥í’ˆ",
    "ì‹í’ˆ": "ê±´ê°•ì‹í’ˆ",
}

# 1. ì¹´í…Œê³ ë¦¬ ë­í‚¹ ìƒì„±
def fetch_naver_shopping_ranking():
    ranking_list = []
    rank_counter = 1
    logger.info("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")

    for category_name, keyword in CATEGORY_KEYWORD_MAP.items():
        logger.debug("ì¹´í…Œê³ ë¦¬ %s: í‚¤ì›Œë“œ %s ìˆ˜ì§‘ ì‹œì‘", category_name, keyword)
        shopping_data = get_naver_shopping_data(keyword)
        items = shopping_data.get("items", [])

        if not items:
            ranking_list.append({
                "rank": rank_counter,
                "keyword": f"[{category_name}] ë°ì´í„° ì—†ìŒ",
                "searchRatio": 0
            })
            rank_counter += 1
            continue

        for item in items[:10]:
            clean_title = item["title"].replace("<b>", "").replace("</b>", "")
            ranking_list.append({
                "rank": rank_counter,
                "keyword": f"[{category_name}] {clean_title}",
                "searchRatio": 0
            })
            rank_counter += 1

    return ranking_list

# 2. í‚¤ì›Œë“œ ì‹œì¥ì„± ë¶„ì„
def analyze_market(items, keyword, total_results, avg_search_ratio):
    if not items:
        return None

    try:
        prices = [int(item['lprice']) for item in items]
        avg_price = int(statistics.mean(prices))
        min_price = min(prices)
        top_item = items[0]['title'].replace("<b>", "").replace("</b>", "")

        return {
            "searchKeyword": keyword,
            "category": items[0].get("category1", "Unknown"),
            "averagePrice": avg_price,
            "lowestPrice": min_price,
            "sampleCount": len(items),
            "topItemName": top_item,
            "totalListings": total_results,
            "competitionLevel": "ë³´í†µ",
            "searchVolumeRatio": avg_search_ratio,
            "marketAttractiveness": "ë†’ìŒ",
            "sourcingScore": avg_search_ratio
        }
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë¶„ì„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return None


# =========================================================
# ğŸ“¤ ë°±ì—”ë“œ ì „ì†¡ í•¨ìˆ˜
# =========================================================

def send_ranking_to_backend(data):
    url = f"{SPRING_BOOT_API}/market/ranking/receive"
    try:
        logger.info("ğŸ“¤ ë­í‚¹ ì „ì†¡ ì‹œë„ - URL=%s, í•­ëª©=%d", url, len(data))
        # âš ï¸ (ì¶”ê°€) ë­í‚¹ ì „ì†¡ ì‹œì—ë„ HTTPS í™˜ê²½ì´ë¼ë©´ verify=False ì¶”ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
        response = requests.post(url, json=data, timeout=5, verify=False)
        response.raise_for_status()
        logger.info("âœ… ë­í‚¹ ë°ì´í„° ì „ì†¡ ì™„ë£Œ - status=%s", response.status_code)
    except Exception as e:
        logger.error(f"âŒ ë­í‚¹ ì „ì†¡ ì‹¤íŒ¨ ({url}): {e}")

def send_analysis_to_backend(data):
    url = f"{SPRING_BOOT_API}/market/analysis"
    try:
        logger.info(f"ğŸ“¤ ë°±ì—”ë“œë¡œ ì „ì†¡ ì‹œë„: {url}")
        # â­ ìµœì¢… ìˆ˜ì •: SSL ê²½ê³  ë¬´ì‹œ ì˜µì…˜ (verify=False) ìœ ì§€
        res = requests.post(url, json=data, timeout=5, verify=False)
        res.raise_for_status()
        logger.info("ğŸš€ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„±ê³µ!")
    except Exception as e:
        logger.error(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")


# =========================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# =========================================================
if __name__ == "__main__":

    # â­â­ ë°œí‘œë¥¼ ìœ„í•´ InsecureRequestWarning ìˆ¨ê¸°ê¸° â­â­
    try:
        # urllib3 ê²½ê³ ë¥¼ í•„í„°ë§í•˜ê¸° ìœ„í•´ requests.packagesë¥¼ í†µí•´ import
        from requests.packages.urllib3.exceptions import InsecureRequestWarning
        warnings.filterwarnings("ignore", category=InsecureRequestWarning)
    except ImportError:
        # requests 2.x ë²„ì „ì—ì„œëŠ” requests.packagesë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        pass
    # -------------------------------------------------

    print("\n" + "="*60)
    print("   ğŸš€ SMART SOURCING WORKER (DOCKER/AWS)")
    print(f"   ğŸ“¡ Target Backend: {SPRING_BOOT_API}")
    print(f"   ğŸ“¬ SQS Queue: {QUEUE_URL}")
    print("="*60 + "\n")

    # 1. ì‹œì‘ ì‹œ ë­í‚¹ ë°ì´í„° 1íšŒ ê°±ì‹ 
    try:
        ranking = fetch_naver_shopping_ranking()
        send_ranking_to_backend(ranking)
    except Exception as e:
        logger.error(f"âš ï¸ ì´ˆê¸° ë­í‚¹ ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")

    logger.info("âš¡ SQS ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸° ì‹œì‘ (Polling)...")

    # 2. ë¬´í•œ ë£¨í”„ (ë©”ì‹œì§€ ì²˜ë¦¬)
    while True:
        try:
            # 20ì´ˆ ë¡± í´ë§ (ë¹„ìš© ì ˆê° ë° íš¨ìœ¨ì„±)
            response = sqs_client.receive_message(
                QueueUrl=QUEUE_URL,
                MaxNumberOfMessages=1,
                WaitTimeSeconds=20
            )

            messages = response.get("Messages", [])
            logger.debug("SQS í´ë§ ê²°ê³¼ - ë©”ì‹œì§€ ìˆ˜: %d", len(messages))

            if not messages:
                continue # ë©”ì‹œì§€ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ë‹¤ì‹œ ëŒ€ê¸°

            for message in messages:
                receipt_handle = message['ReceiptHandle']
                body_str = message['Body']

                logger.info(f"\nğŸ“© [SQS] ë©”ì‹œì§€ ë„ì°©: {body_str}")

                try:
                    # JSON íŒŒì‹±
                    body = json.loads(body_str)
                    keyword = body.get('keyword')

                    if not keyword:
                        logger.error("âŒ í‚¤ì›Œë“œê°€ ì—†ëŠ” ì˜ëª»ëœ ë©”ì‹œì§€ì…ë‹ˆë‹¤.")
                        sqs_client.delete_message(QueueUrl=QUEUE_URL, ReceiptHandle=receipt_handle)
                        continue

                    logger.info(f"ğŸ” ë¶„ì„ ì‹œì‘: [{keyword}]")

                    # ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
                    shopping = get_naver_shopping_data(keyword)
                    items = shopping.get("items", [])
                    total = shopping.get("total", 0)
                    trend = get_naver_datalab_trend(keyword)

                    result = analyze_market(items, keyword, total, trend)

                    # ë°±ì—”ë“œ ì „ì†¡Ã
                    if result:
                        logger.debug("ë¶„ì„ ê²°ê³¼ payload: %s", result)
                        send_analysis_to_backend(result)
                    else:
                        logger.warning("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ì „ì†¡í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                    # ì²˜ë¦¬ ì™„ë£Œ í›„ ë©”ì‹œì§€ ì‚­ì œ (í•„ìˆ˜)
                    sqs_client.delete_message(
                        QueueUrl=QUEUE_URL,
                        ReceiptHandle=receipt_handle
                    )
                    logger.info("ğŸ—‘ï¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ ë° ì‚­ì œë¨")

                except json.JSONDecodeError:
                    logger.error("âŒ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
                    sqs_client.delete_message(QueueUrl=QUEUE_URL, ReceiptHandle=receipt_handle)
                except Exception as e:
                    logger.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    # ì—¬ê¸°ì„œ ë©”ì‹œì§€ë¥¼ ì§€ìš°ì§€ ì•Šìœ¼ë©´, ì¼ì • ì‹œê°„ í›„ ë‹¤ì‹œ íì— ë‚˜íƒ€ë‚˜ ì¬ì‹œë„ë©ë‹ˆë‹¤ (Visibility Timeout)

        except KeyboardInterrupt:
            print("\nğŸ›‘ ì›Œì»¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(0)
        except Exception as e:
            logger.critical(f"ğŸ”¥ SQS ì—°ê²° ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            time.sleep(10) # ì—ëŸ¬ ë°œìƒ ì‹œ 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„